# 4. 메모리
## 4.1 메모리 역사
메모리 종류   
- Core memory   
- 진공관 메모리   
- 트랜지스터 메모리   
- 집적회로 메모리 : SRAM, DRAM   
   
1970년대부터 현재까지 메모리 용량은 KB 단위에서 GB 단위로 늘어왔다.   
그러나 그에 따라 처리해야할 데이터의 복잡성이나 프로그램 크기도 증가하기 때문에 언제나 메모리는 부족하다.   
메모리 효과적으로 사용할 수 있는 방법 : 메모리 낭비 없애기 + 가상 메모리   

## 4.2 메모리 주소
프로그램 개발   
- 원천 파일(Sourse file) : 고수준 언어 또는 어셈블리 언어   
- 목적 파일(Object file) : 컴파일 또는 어셈블의 결과   
- 실행 파일(Executable file) : 링크 결과   
<img width='500px' src='https://user-images.githubusercontent.com/31424628/147451032-46da86c3-ce28-42a7-92d1-cb9af58d9691.png' />
   
개발 도구 : compiler, assembler, linker, loader   
프로그램 실행(파일) : code + data + stack   
   
실행 파일을 메모리에 올리기 위해서는   
1) 메모리 몇 번지에 올릴 지, 2) 다중 프로그래밍 환경에서는 어떻게 할 지   
등을 고려해야 하는데, 이를 해결하기 위해 MMU를 사용한다. 파일이 메모리에 적재되는 주소가 매번 다르기 때문에 사용한다.   
* MMU(Memory Management Unit) : 주소를 중간에서 감시하는 역할. base, limit, relocation 레지스터 등으로 구성되어 있다.   
- 재배치 레지스터 : CPU와 메모리 중간에서 주소를 감시하고 변환(translation)한다.   
  ex) CPU는 hwp 파일을 실행하며 0번 주소를 건넨다. OS는 hwp의 시작 주소인 1000번지를 MMU에 기록한다.   
      CPU는 0번에 hwp 파일이 적재돼 있다고 생각하지만 사실을 1000번에 있는 것이다.   
즉 주소는 CPU가 건네는 논리(logical) 주소와 실제 메모리 안의 물리(physical) 주소가 있는 것이다.   
   
## 4.3 메모리 낭비 방지
(1) 동적 적재 (Dynamic Loading)   
: 프로그램 실행에 반드시 필요한 루틴/데이터만 적재   
- 모든 루틴(조건문 오류 처리 등) 혹은 데이터(배열 넉넉히 선언)가 다 사용되는 것은 아니기 때문에   
- 실행 시 필요하면 그때 해당 부분을 메모리에 올린다.
   
(2) 동적 연결 (Dynamic Linking)   
- 여러 프로그램에 공통으로 사용되는 라이브러리 루틴을 메모리에 중복으로 올리는 것은 낭비   
- 라이브러리 루틴 연결(link)를 실행 시까지 미룬다.   
- 오직 하나의 라이브러리 루틴만 메모리에 적재되고 다른 앱 실행 시 이 루틴과 연결된다.   
- 공유 라이브러리(shared library in Linux), 동적 연결 라이브러리(DLL in Windows)   
   
(3) 스와핑   
- 메모리 활용도를 높이기 위해 사용중이 아닌 프로세스 이미지를 backing store(=swap device)로 몰아냄   
- swap out vs swap in   
- Relocation register 사용으로 적재 위치는 무관   
- 프로세스 크기가 크면 backing store 입출력에 따른 부담이 크다. (하드디스크라 느림)   
- 사용 안해 몰아낸 프로세스 이미지(code + data + stack)는 기존 하드디스크의 실행 파일(code + data)과 다름.   

## 4.4 연속 메모리 할당
Contiguous Memory Allocation   
다중 프로그래밍 환경   
- 부팅 직후 메모리 상태 : OS + big single hole   
- 프로세스 생성 & 종료 반복 -> scattered holes   
   
메모리 단편화 (Memory fragmentation)   
- Hole 들이 불연속하게 흩어져 있기 때문에 프로세스 적재 불가   
- 외부 단편화 (external fragmentation) 발생   
- 외부 단편화를 최소화 하려면 어떡해야 할까?   
   
연속 메모리 할당 방식   
- First-fit(최초 적합) : 가장 먼저 나오는 메모리 hole에 할당   
- Best-fit(최적 적합) : 사이즈가 제일 비슷한 곳에 할당   
- Worst-fit(최악 적합) : 가능한 선택지 중 가장 안맞는 곳에 할당   
   
할당 방식 성능 비교 : 속도 및 메모리 이용률   
- 속도 : first-fit   
- 이용률 : first-fit, best-fit   
   
외부 단편화로 인한 메모리 낭비   
- 1/3 수준 (사용 불가 수준)   
- Compaction : 최적 알고리즘이 없음. OS가 hole들을 한 곳으로 모아줘야 해 부담이 큼.   
   
## 4.5 페이징(Paging)
프로세스를 일정 크기(=페이지)로 잘라서 메모리에 넣는 방식   
- 프로세스는 페이지의 집합   
- 메모리는 프레임(frame)의 집합   
- 페이지를 프레임에 할당   
   
MMU 내의 재배치 레지스터 값을 바꿈으로서 CPU는 프로세스가 연속된 메모리 공간에 위치한다고 착각하게 된다.   
MMU는 page table이라고 불리게 된다.   
   
논리 주소 (Logical address)   
- CPU가 내는 주소는 2진수로 표현 (전체 m 비트)   
- 하위 n 비트는 오프셋(offset) 또는 변위(displacement)   
- 상위 m-n 비트는 페이지 번호   
   
주소 변환 (Address translation)   
- 논리 주소 -> 물리 주소   
- 페이지 번호(p)는 페이지 테이블의 인덱스 값   
- p에 해당되는 테이블 내용이 프레임 번호(f)   
- 변위(d)는 변하지 않음   
- 예제는 프린트의 필기 참조   
   
내부 단편화 (Internal Fragmentation)   
- 프로세스 크기가 페이지 크기의 배수가 아니라면(나머지가 있다면),   
- 마지막 페이지는 한 프레임을 다 채울 수 없다.   
- 남는 공간 = 메모리 낭비. 물론 낭비가 미미하긴 하다.   
   
페이지 테이블 만들기   
- CPU 레지스터로 (CPU 안에 page table 만들 때) : 주소 변환 속도가 빠름, CPU 내부이므로 용량이 딸림   
- 메모리로 (메모리 안에 page table 만들 때) : 용량이 넉넉함, 주소 변환 속도가 느림   
- TLB (Translation Look-aside Buffer)로 : 별도의 속도 빠른 캐시 메모리(S-RAM) 사용, 위 두개의 장단점을 섞음   
- 척도 : 테이블 엔트리 개수(메모리 승) vs 변환 속도(CPU 승)   
   
보호 (Protection) : 해킹 등을 방지   
- 모든 주소는 페이지 테이블을 경유하므로, 페이지 테이블 엔트리마다 r, w, x 비트를 둬 해당 페이지에 대한 접근을 제어한다.   
- r(read), w(write), x(execute)   
   
공유 (Sharing) : 메모리 낭비 방지   
- 같은 프로그램을 쓰는 복수 개의 프로세스가 있다면 code + data + stack에서 code는 공유 가능. ex) hwp 파일 3개 띄워 놓기   
- 단, 실행하며 스스로 코드를 바꾸지 않는 non-selfmodifying code (= reentrant code 재진입 코드 = pure code) 인 경우만 가능   
- 프로세스의 페이지 테이블 코드 영역이 같은 곳을 가리키게 해 코드를 공유한다.   
   
## 4.6 세그멘테이션 (Segmentation)
프로세스를 논리적 내용(=segment)로 잘라서 메모리에 배치   
- 프로세스는 세그멘트의 집합   
- 세그멘트의 크기는 일반적으로 같지 않다.   
   
세그멘트를 메모리에 할당   
- MMU 내의 재배치 레지스터 값을 바꿈으로서 CPU는 프로세스가 연속된 메모리 공간에 위치한다고 착각   
- MMU는 세그멘트 테이블 (segment table)이 된다.   
- 논리(logical) 주소 : CPU가 내는 주소는 segment 번호(s) + 변위(d)   
   
주소 변환
- 논리 주소 -> 물리 주소   
- 세그멘트 테이블 내용 : base + limit   
- 세그멘트 번호(s)는 세그멘트 테이블 인덱스 값   
- s에 해당되는 테이블 내용으로 시작 위치 및 한계값 파악   
- 한계(limit)를 넘어서면 segment violation 예외 상황 처리   
- 물리 주소 = base[s] + d   
   
보호 (Protection)   
- 설명은 페이징의 경우와 같다.   
- 페이징에서의 보호보다 우월하다.
- 페이징은 정해진 크기로 잘라서 code, data, stack이 섞여 r,w,x를 설정하기 애매하기 때문이다.   
   
공유 (Sharing)   
- 설명은 페이징의 경우와 같다.   
- 마찬가지로 페이징에서의 공유보다 우월하다.   
- 공유에서도 페이징은 code,data,stack이 섞여 코드 공유가 애매하기 때문이다.   
   
외부 단편화 (External Fragmentation)   
- 세그멘트 크기는 고정이 아니라 가변적   
- 크기가 다른 각 세그멘트를 메모리에 두려면 동적 메모리 할당을 해야한다.   
- 연속 메모리 할당과 같이 first-, best-, worst-fit, compaction 등의 문제가 발생한다.   
- 외부 단편화 문제를 해결하지 못하는 것이다.   
   
세그멘테이션 + 페이징   
- 세그멘테이션은 보호와 공유면에서 효과적   
- 페이징은 외부 단편화 문제를 해결   
- 따라서 세그멘트를 페이징하는 방법이 고안됨 -> paged segmentation   
- 그러나 주소 변환할 때마다 두 개의 테이블을 통과해야 하므로 속도가 느려진다는 단점이 존재한다.   


