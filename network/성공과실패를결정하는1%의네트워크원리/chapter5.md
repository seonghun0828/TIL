# 서버측의 LAN에는 무엇이 있는가?
[1. 웹 서버의 설치 장소](#1-웹-서버의-설치-장소)   
[2. 방화벽의 원리와 동장](#2-방화벽의-원리와-동작)   
[3. 복수 서버에 리퀘스트를 분배한 서버의 부하 분산](#3-복수-서버에-리퀘스트를-분배한-서버의-부하-분산)   
[4. 캐시 서버를 이용한 서버의 부하 분산](#4-캐시-서버를-이용한-서버의-부하-분산)   
[5. 콘텐츠 배포 서비스](#5-콘텐츠-배포-서비스)   

## 1 웹 서버의 설치 장소
    1. 사내에 웹 서버를 설치하는 경우   
현재 이 방법은 주류에서 밀려났다. IP 주소의 부족과 보안상의 이유 때문이다.   
지금은 사내 LAN과 서버를 분리해 방화벽을 두는 방법이 일반화되었다.   

    2. 데이터센터에 웹 서버를 설치하는 경우   
데이터센터라는 시설에 서버를 가지고 들어가거나 프로바이더 등이 소유하는 서버를 빌려쓴다.   
프로바이더들은 인터넷의 중심 부분에 고속 회선으로 접속되었으므로 고속으로 액세스가 가능하다.   
또 데이터센터는 내진 구조, 자가 발전, 24시간 관리 등 회사 안보다 안전성이 높다.   

## 2 방화벽의 원리와 동작
    1. 패킷 필터링형이 주류이다   
서버의 설치 장소와 관계 없이 지금은 바로 앞에 방화벽이 보통 존재한다.   
방화벽은 특정 서버와 해당 서버 안의 특정 애플리케이션에 액세스하는 패킷만 통과시키고 그 외 패킷은 차단한다.   
네트워크에는 다양한 패킷이 흐르고 있으므로 어떤 패킷을 통과 혹은 차단할지 선별하기 위해 다양한 방법이 고안되었다.   
현재 가장 많이 보급된 방법은 패킷 필터링형 방화벽이다.   

    2. 패킷 필터링의 조건 설정 개념   
패킷의 헤더에는 통신 동작을 제어하는 제어 정보가 들어있다. 그중 패킷 필터링의 조건 설정에서 자주 사용되는 것은 다음과 같다.   
1) MAC 헤더(송신처 MAC 주소), 2) IP 헤더(송신처 IP 주소, 수신처 IP 주소, 프로토콜 번호),   
3) TCP 헤더 또는 UDP 헤더(송신처 포트 번호, 수신처 포트 번호, TCP 컨트롤 비트, 프래그먼트), 4) 헤더가 아니라 ICMP 메시지의 내용   
   
패킷 필터링의 조건을 설정할 때는 먼저 패킷의 흐름에 착안한다. 수신처 IP 주소와 송신처 IP 주소에 따라 시점과 종점을 판단한다.   
인터넷에서 웹 서버로 흐르는 패킷은 보낼 때의 시점은 지정할 수 없지만, 종점은 웹 서버가 되므로 이것을 조건으로 설정할 수 있다.   
송신처 IP 주소에 따라 시점을 지정할 수 있으면 이것도 조건에 추가한다.   
   
서버에서 인터넷으로 액세스하는 것은 부정 소프트웨어의 감염을 막기 위해 기본적으로 금지하고 있다.   
그러나 패킷을 받으면 정확히 도착했는지를 송신측에 알리는 수신 확인 응답 구조가 작용하므로 웹 서버에서 인터넷으로 흐르는 패킷도 있다.   
이 패킷도 웹 서버에서 인터넷측으로 흘러간 후 그곳에서 시점(송신처 IP 주소)이 웹 서버의 주소와 일치하는 패킷은 통과한다.
   
기본적으로 수신처나 송신처의 주소가 패킷을 통과시킬 것인지 차단할 것인지를 결정하는 첫걸음인 것이다.   

    3. 애플리케이션을 한정할 때 포트 번호를 사용한다   
보안에서는 어떤 패킷이 어떤 위험성이 잠재하는지 모르기 때문에 불필요한 것은 전부 차단하고 필요한 것만 허용하는 방법이 좋다.   
지금처럼 웹을 사용하고 있을 때는 웹 애플리케이션으로 한정하는 것이 좋은 것이다.   
   
특정 애플리케이션으로 조건을 한정할 때는 TCP 헤더나 UDP 헤더에 기록되어 있는 포트 번호를 조건으로 추가한다.   
웹 서버의 포트 번호는 80번으로 결정되어 있으므로 전술한 수신처 IP 주소 및 송신처 IP 주소에 수신처 포트 번호가 80번인 경우의 조건도 추가한다.   
웹 서버 이외의 애플리케이션에 대한 액세스를 허가할 경우에는 이 애플리케이션의 포트 번호를 설정해 이것이 통과하도록 한다.   

    4. 컨트롤 비트로 접속 방향을 판단한다   
웹의 동작은 TCP 프로토콜을 사용해 양방향으로 패킷이 흐른다.    
그러므로 단순히 웹 서버에서 인터넷으로 흐르는 패킷을 정지시키면 인터넷에서 웹 서버에 액세스하는 동작도 정지되는 것이다.   
패킷이 흐르는 방향이 아니라 액세스 방향을 판단해 정지시켜야 하는데, 여기에서 TCP 헤더의 컨트롤 비트를 활용할 수 있다.   
   
TCP는 최초에 행하는 접속 단계의 동작에서 3개의 패킷이 흐르는데, 최초의 패킷만 TCP 컨트롤 비트의    
SYN이라는 비트가 1이 되고, ACK라는 비트가 0이 된다. 이 값을 조사해 최초의 패킷과 그 이후 패킷을 판별할 수 있다.   
   
최초의 패킷이 웹 서버측에서 인터넷측으로 흘러갈 경우 이것을 차단하도록 설정한다.   
이것을 차단하면 상대로부터 두 번째 패킷이 돌아오는 경우가 없으므로 당연히 TCP의 접속 동작은 실패로 끝난다.   
웹 서버가 기점이 되어 인터넷에 액세스하려고 해도 접속 동작이 틀림 없이 실패한다는 것이다.   
   
인터넷측에서 웹 서버에 액세스할 때는 최초의 패킷은 수신처가 웹 서버를 나타내고 컨트롤 비트가 SYN=1, ACK=0이므로 통과한다.   
두 번째 패킷은 송신처가 웹 서버를 나타내지만, 컨트롤 비트가 SYN=0, ACK=1이므로 통과한다.   
결국 인터넷측에서 웹 서버에 액세스할 때 흐르는 패킷은 전부 패킷 필터링을 통과하는 것이다.   
   
실제로는 통과시키는 것과 차단하는 것을 완전히 선별할 수 없는 경우도 있는데, DNS 서버에 대한 액세스가 대표적인 예다.   
DNS 서버에 조회하는 동작은 UDP를 사용하는데, UDP는 접속 단계의 동작이 없으므로 액세스 방향을 판별할 수 없다.   
이 성질은 UDP를 사용하는 애플리케이션에 공통이다. 이 경우에는 패킷을 전부 통과시키거나, 전면 차단하는 방법을 선택해야 한다.   

    5. 사내 LAN에서 공개 서버용 LAN으로 조건을 설정한다   
인터넷과 공개 서버용 LAN(서버)을 왕래하는 패킷의 조건을 설정할 뿐 아니라    
사내 LAN과 인터넷 또는 사내 LAN과 공개 서버용 LAN을 왕래하는 패킷의 조건도 설정해야 합니다.   

    6. 밖에서 사내 LAN으로 액세스할 수 없다   
패킷 필터링형 방화벽은 패킷을 통과시킬지, 차단시킬지를 판단할 뿐만 아니라 주소 변환의 기능도 가지고 있다.   
인터넷과 사내 LAN을 왕래하는 패킷은 주소 변환을 해야 하므로 설정이 필요합니다.   
주소 변환을 이용하면 인터넷측에서 사내 LAN에는 액세스할 수 없게 된다.   

    7. 방화벽을 통과한다   
방화벽에 의해 패킷이 차단되면 패킷을 버리고, 버린 기록은 남긴다. 부정 침입 흔적을 분석해 향후 활용하기 위해서다.   
통과시킨다는 판정을 내린 경우 패킷을 중계하는데, 이 중계 동작은 라우터의 동작과 같다.   
복잡한 조건 설정이나 버린 패킷의 기록이 필요하지 않으면 전용 하드웨어나 소프트웨어를 사용하지 않고 패킷 필터링 기능을 가진 라우터를 방화벽으로 사용할 수 있다.   

    8. 방화벽으로 막을 수 없는 공격
방화벽은 시점과 종점만 조사하므로 패킷의 내용을 조사하지 않으면 위험한지 판단할 수 없어 방화벽의 구조는 이런 상황에 대처할 수 없다.   
두 가지 대처법이 있는데, 웹 서버를 항상 새로운 버전으로 갱신해 보안을 유지하는 것이다.   
또 하나는 방화벽과는 별도로 패킷의 내용을 조사해 위험한 데이터가 포함된 경우 패킷을 차단하는 것이다.

## 3 복수 서버에 리퀘스트를 분배한 서버의 부하 분산
    1. 처리 능력이 부족하면 복수 서버로 부하 분산된다   
대량의 패킷에 서버의 처리 능력이 부족해지면 서버 머신을 고성능으로 교체하는 것이 가장 먼저 떠오르는 방법이다.   
이때 다수의 사용자가 집중적으로 액세스하면 아무리 고성능 기종이라 할 지라도 서버 한대로는 따라잡지 못할 것이다.   
그럴 때 복수의 서버를 사용해 처리를 분담하는 분산 처리 방법을 사용하고, 분산 처리에는 여러 방식이 있다.   
   
가장 간단한 방법은 여러 대의 웹 서버를 설치하고 한 대가 담당하는 사용자 수를 줄이는 방법이다.   
이 방법을 취할 경우 클라이언트가 보내는 리퀘스트를 웹 서버에 분배하는 구조가 필요하다.   
구체적인 방법 중 DNS 서버에서 분배하는 방법이 가장 간단하다.   
   
서버에 액세스할 때 DNS 서버에 조회하여 IP 주소를 조사하는데, DNS 서버에 같은 이름으로 여러 대의 웹 서버를 등록해 놓는다.   
그러면 DNS 서버는 조회가 있을 때마다 차례대로 IP 주소를 되돌려주는 것이다.   
   
www.github.com 이라는 서버명에 A, B, C라는 3개의 IP 주소를 대응시킨다고 가정해본다.   
최초의 조회에는 A B C 라고 3개를 나란히 회답하고, 다음 조회에는 B, C, A를, 다음에는 C, A, B를 회답한다는 식이다.   
그리고 1주기를 순환하고 원래대로 돌아가는데 이 방법을 ***라운드 로빈***이라고 한다.   
   
이 방법에는 결점이 있는데, 웹 서버가 많으면 이 중 고장나는 것도 있을 것이다. 이때 고장난 웹 서버를 피해서   
IP 주소를 회답하면 좋지만, 보통 DNS 서버는 웹 서버의 동작 유무를 확인하지 못하므로 웹 서버가 정지해도 상관 않고 IP 주소를 회답해 버린다.   
   
라운드 로빈에서 차례대로 웹 서버를 분배하면 좋지 않은 상태가 생길 수 있다.   
CGI 등의 애플리케이션에서 페이지를 동적으로 만드는 경우 복수의 페이지에 걸쳐 대화할 수 있는데, 웹 페이지가 변하면 대화가 도중에 끊길 수 있기 때문이다.   
쇼핑 사이트에서 첫 번째 페이지에 주소나 이름을 입력하고, 다음 페이지에서 신용카드 번호를 입력하는 것과 같은 경우가 있다.   

    2. 부하 분산 장치를 이용해 복수의 웹 서버로 분할된다   
이런 좋지 않은 상태를 피하기 위해 ***부하 분산 장치*** 또는 ***로드 밸런서*** 등으로 부르는 기기가 고안되었다.   
먼저 부하 분산 장치를 웹 서버 대신 DNS 서버에 등록한다. 그러면 클라이언트는 여기에 리퀘스트 메시지를 전송한다.   
그러면 어느 웹 서버에 리퀘스트를 전송해야 할지 판단해야 하는데, 우선 대화가 복수의 페이지에 걸쳐있는지에 따라 판단 기준이 달라진다.   
   
복수 페이지에 걸쳐있지 않은 단순 액세스라면 웹 서버의 부하 상태가 판단 근거가 된다.   
웹 서버와 정기적으로 정보를 교환해 CPU나 메모리의 사용률을 수집하고, 이것을 바탕으로 부하가 낮은 웹 서버를 판단한다.   
혹은 시험 패킷을 웹 서버에 보내 응답 시간으로 부하를 판단하거나, 미리 웹 서버의 능력 비율에 따라 리퀘스트를 분배할 수도 있다.   
   
대화가 복수 페이지에 걸쳐있을 때는 웹 서버 부하에 관계 없이 이전 리퀘스트와 같은 웹 서버에 전송한다.   
그러나 HTTP 기본 동작은 리퀘스트 메시지를 보내기 전에 TCP 접속 동작을 하고, 응답 메시지를 반송하면 연결을 끊는다.    
즉, HTTP 상의 연결은 connectless해 stateless한 특징을 가지고 있으므로 대화가 복수 페이지에 걸쳐있는지 확인할 수 없다.   
이런 문제를 해결하기 위해 HTTP 헤더 필드에 전후 관계를 판단하기 위한 정보를 추가하는 방법(쿠키)을 사용한다.

## 4 캐시 서버를 이용한 서버의 부하 분산
    1. 캐시 서버의 이용   
여러 대 웹 서버를 설치하는 것이 아니라 다른 방법으로 부하 분산을 하는 방법도 있다.   
데이터베이스 서버와 웹 서버 같은 역할에 따라 서버를 나누는 방법으로, 캐시 서버를 사용하는 방법이다.    
   
캐시 서버는 ***프록시***라는 구조를 사용해 데이터를 캐시에 저장하는 서버다. 프록시는 웹 서버와 클라이언트 사이에 들어가 웹 서버에 대한 액세스 동작을 중개한다.   
이때 프록시는 웹 서버에서 받은 데이터를 디스크에 저장해 두고 웹 서버를 대신해 데이터를 클라이언트에 반송하는 기능을 가지고 있다.   
이것을 캐시라고 부른다. 웹 서버는 내부에서 여러 처리를 하기 때문에 시간이 걸리는 반면, 캐시 서버는 보존해 둔 데이터를 읽어 송신만 하므로 보다 빠르다.   
    
    2. 캐시 서버는 갱신일로 콘텐츠를 관리한다   
캐시 서버를 사용할 때는 부하 분산 장치와 마찬가지로 캐시 서버를 웹 서버 대신 DNS 서버에 등록한다.   
사용자가 캐시 서버에 HTTP 리퀘스트 메시지를 보내면 캐시 서버는 메시지의 내용을 조사하고, 데이터가 자신의 캐시에 저장되었는지 조사한다.   
   
1) 데이터가 캐시에 저장되어 않은 경우    
캐시 서버는 리퀘스트 메시지에 캐시 서버를 경유한 것을 나타내는 'Via'라는 헤더 필드를 추가해 웹 서버에 전송한다.   
만약 한 대의 캐시로 여러 대의 서버의 데이터를 캐시에 저장하는 경우 리퀘스트 메시지의 내용에 따라 몇 가지 방법으로 전송 대상의 웹 서버를 판단한다.    
대표적으로 리퀘스트 메시지의 URI에 쓰여있는 디렉토리를 보고 판단하는 방법이 있다.    
예) URI가 /dir1/이라는 디렉토리였다면 www1.github.com에 전송한다. URI가 /dir2/라는 디렉토리라면 www2.github.com에 전송한다.   
   
이때 전송 대상의 웹 서버에 대해 캐시 서버가 클라이언트가 되어 리퀘스트 메시지를 보낸다. 소켓을 만들고 웹 서버의 소켓에 접속해 송신하는 식이다.   
그러면 웹 서버에서 보내는 응답 메시지는 캐시 서버에 돌아온다.    
이번에는 클라이언트에 대해 웹 서버가 되어 'Via' 헤더 필드를 부가해 응답 메시지를 전송한다. 그 응답 메시지는 캐시에 저장하고 저장한 일시를 기록한다.   
   
이렇게 클라이언트와 웹 서버 사이를 중개하는 것이 프록시 구조이다. 중개할 때 페이지의 데이터를 저장하면 캐시 서버에 데이터가 축적된다.   
그러면 사용자가 액세스한 페이지가 캐시 서버에 저장되어 있는 경우가 증가한다.
   
2) 데이터가 캐시 서버에 저장되어 있는 경우   
먼저 사용자로부터 도착한 리퀘스트 메시지를 받아 캐시에 저장되었는지 조사한다.    
웹 서버측에서 데이터가 변경되었는지 조사하기 위해 'If-Modified-Since'라는 헤더 필드를 추가해 웹 서버에 전송한다.   
웹 서버는 'If-Modified-Since' 헤더 필드의 값과 페이지 데이터의 최종 갱신 일시를 비교해 변경이 없으면 변경이 없다는 응답 메시지를 반송한다.   
   
응답 메시지가 캐시 서버에 도착하면 캐시에 저장한 데이터가 최신 데이터와 같은지 알 수 있다.   
같다면 캐시 서버는 캐시에서 데이터를 추출해 사용자에게 보낸다.   
웹 서버측에서 데이터가 변경된 경우에는 캐시에 데이터가 저장되어 있지 않은 경우와 같이 동작한다.   
웹 서버는 최신 데이터를 반송하므로 메시지에 'Via' 헤더를 부가해 사용자에게 전송하고 데이터를 캐시에 저장한다.   

    3. 프록시의 원점은 포워드 프록시이다   
지금까지는 프록시라는 구조를 웹 서버측에 두고 캐시 기능을 사용한 것이었지만, 클라이언트측에 캐시 서버를 두는 방법도 있다.   
캐시 서버에서 이용하는 프록시라는 구조는 원래 클라이언트측에 두는 방법에서 시작했다. 이것이 프록시의 원형으로, ***포워드 프록시***라고 한다.   
포워드 프록시는 애초에 캐시를 이용하는 것에 추가적으로, 방화벽을 실현한다는 목적이 하나 더 있었다.   
   
우선 클라이언트측에 프록시 구조를 둘 때, 사내 LAN에서 프록시에 액세스하기만 하면 데이터를 손에 넣을 수 있으므로 매우 빨라진다.   
또 프록시는 리퀘스트의 내용을 조사한 후 전송하므로 리퀘스트 내용에 따라 액세스가 가능한지 판단이 가능하다.   
패킷 필터링형 방화벽보다 보다 자세히 조건을 설정하는 것이 가능한 것이다.   
   
포워드 프록시를 사용할 경우 보통 브라우저의 설정 화면에 준비되어 있는 프록시 서버라는 항목에 포워드 프록시의 IP 주소를 설정한다.
그러면 브라우저의 리퀘스트 메시지 송신 동작과 리퀘스트 메시지가 달라진다.    
   
1) 포워드 프록시를 설정하지 않으면    
브라우저는 URL 입력 상자에 입력된 http://... 문자열에서 액세스 대상 웹 서버를 계산하고, 여기에 리퀘스트를 보낸다.   
URL에서 웹 서버의 이름을 제외하고 파일이나 프로그램 경로명의 일부를 추출하여 이것을 리퀘스트의 URI 부분에 기록한다.   
메시지를 전송할 때는 서버측에 둔 캐시 서버에 설정해 둔 웹 서버에만 전송할 수 있다.
   
2) 포워드 프록시를 설정하면    
URL에 상관 없이 리퀘스트를 전부 포워드 프록시에 보낸다. 리퀘스트의 URI에는 http://... 라는 URL 그대로 기록한다.   
메시지를 전송할 때는 URI 부분에 URL이 그대로 쓰여있으므로 URL이 전송 대상이 된다.   
그러므로 서버측에 두는 캐시 서버와 같이 전송 대상 웹 서버를 사전에 설정해 둘 필요가 없고, 모든 웹 서버에서 전송할 수 있다.   

    4. 포워드 프록시를 개량한 리버스 프록시   
포워드 프록시를 사용할 경우 브라우저에 대한 설정이 꼭 필요하다는 것이 포워드 프록시의 특징이다.   
그런데 이 방법은 브라우저의 설정이 번거롭고 잘못 설정할 가능성이 있어 장애의 원인이 되기도 한다.   
또한 웹 서버는 누가 액세스하는지 알 수 없고, 브라우저에 프록시를 설정할 수 없기 때문에 포워드 프록시를 잘 쓰지 않는다.   
    
이에 브라우저에 프록시를 설정하지 않아도 사용할 수 있도록 개량되었다.   
리퀘스트 메시지의 URI에 쓰여있는 디렉토리명과 전송 대상의 웹 서버를 대응시켜    
URI 부분에 URL 전체가 쓰여있지 않은 보통의 리퀘스트 메시지를 전송할 수 있도록 했다.   
이것이 서버측에 설치하는 캐시 서버에 채택하고 있는 방식인 ***리버스 프록시***이다.

    5. 트랜스페어런트 프록시   
캐시 서버에서 전송 대상을 판단하는 방법, 즉 리퀘스트 메시지에서 패킷의 헤더를 조사하는 방법이 있다.   
패킷의 맨 앞 IP 헤더에는 수신처 IP 주소가 기록돼 있으므로 이것을 조사하면 액세스 대상 웹 서버가 어디 있는지 알 수 있는데,   
이 방법을 트랜스페이런트 프록시라고 부른다.   
   
트랜스페어런트 프록시는 포워드 프록시와 리버스 프록시의 장점만 모은 구조이지만, 여기에 리퀘스트 메시지를 건네주는 방법을 주의해야 한다.   
트랜스페어런트 프록시는 브라우저에 설정하지 않으므로 브라우저는 웹 서버에 리퀘스트 메시지를 보낸다.   
리버스 프록시와 같이 DNS 서버에 등록하는 방법이라면 이 리퀘스트 메시지가 프록시에 도착하지만, 트랜스페어런트 프록시는 DNS 서버에 등록하지 않는다.   
   
DNS 서버에 등록하면 트랜스페어런트 프록시 자체가 액세스 대상이 되어 수신처 IP 주소로 전송 대상의 웹 서버를 판단한다는 구조를 이용할 수 없게 된다.   
그러면 리퀘스트 메시지는 브라우저에서 서버로 흘러갈 뿐 트랜스페어런트 프록시에는 도착하지 않는 것이다.   
   
이것을 해결하기 위해 브라우저에서 서버로 리퀘스트 메시지가 흘러가는 길에 트랜스페어런트 프록시를 설치한다.   
그리고 메시지가 트랜스페어런트 프록시를 통과할 때 그것을 가로챈다.    
리퀘스트 메시지가 흐르는 길이 많으면 여기에 전부 트랜스페어런트 프록시를 설치해야 하므로 길이 한 개로 수렴하는 형태로 네트워크를 만들어   
수렴되는 곳에 트랜스페어런트 프록시를 설치하는 것이 보통이다.   
   
트랜스페어런트 프록시를 사용하면 사용자가 프록시의 존재를 알아차릴 필요가 거의 없어진다.   
따라서 HTTP의 메시지를 전송한다는 구조에 대한 관심이 적어지고 캐시를 이용한다는 측면에서 비중이 높아지고 있다.   
요즘은 프록시라고 부르지 않고 캐시라고 부르는 예가 늘어나고 있다.

## 5 콘텐츠 배포 서비스
    1. 콘텐츠 배포 서비스를 이용한 부하 분산   
    2. 가장 가까운 캐시 서버의 관점   
    3. 리피터용 서버로 액세스 대상을 분배한다   
    4. 캐시 내용의 갱신 방법에서 성능의 차이가 난다
